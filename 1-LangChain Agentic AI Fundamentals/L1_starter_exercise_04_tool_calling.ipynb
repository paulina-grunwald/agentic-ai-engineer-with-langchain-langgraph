{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise - Enable Tool Calling - STARTER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you’ll enhance your AI agent by adding tool-calling capabilities, allowing it to interact with external functions dynamically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Challenge**\n",
    "\n",
    "Imagine you're building an AI-powered assistant that helps users with various tasks such as:\n",
    "\n",
    "- Fetching real-time stock prices\n",
    "- Performing complex calculations\n",
    "- Querying a weather API\n",
    "- Searching a database\n",
    "\n",
    "Instead of manually deciding when to call which function, your AI agent will automatically detect when a tool is needed and invoke it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import the necessary libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /opt/homebrew/lib/python3.11/site-packages (1.2.1)\n",
      "Requirement already satisfied: pendulum in /opt/homebrew/lib/python3.11/site-packages (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6 in /Users/paulina/Library/Python/3.11/lib/python/site-packages (from pendulum) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2020.1 in /opt/homebrew/lib/python3.11/site-packages (from pendulum) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/paulina/Library/Python/3.11/lib/python/site-packages (from python-dateutil>=2.6->pendulum) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/opt/homebrew/opt/python@3.11/bin/python3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv pendulum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import datetime\n",
    "import inspect\n",
    "import json\n",
    "from typing import (\n",
    "    TypedDict,\n",
    "    List, Dict, Literal,\n",
    "    Callable, Optional, Any,\n",
    "    get_type_hints\n",
    ")\n",
    "from openai import OpenAI\n",
    "from openai.types.chat.chat_completion_message import ChatCompletionMessage\n",
    "from openai.types.chat.chat_completion_message_tool_call import ChatCompletionMessageToolCall\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Recap: how to use OpenAI client with your API Key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to connect with OpenAI, you need to instantiate an OpenAI client passing your OpenAI key.\n",
    "\n",
    "You can pass the `api_key` argument directly.\n",
    "```python\n",
    "client = OpenAI(api_key=\"voc-\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(\"../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "     api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    base_url=\"https://openai.vocareum.com/v1\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm focused on Python programming, so I don't have information about the Java Virtual Machine or other languages. However, if you have any questions about Python, feel free to ask!\""
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt = \"Act as Senior Python Programmer. You don't know anything about other programming language, so don't provide answers about languanges like like Java.\"\n",
    "user_question = \"What is the Java Virtual Machine?\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_question},\n",
    "        ],\n",
    "        temperature=0.0,\n",
    "    )\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Recap: Memory & Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recently we combined memory with custom Python functions to create the full cycle of tool calling, which enabled an LLM to interact with the world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory:\n",
    "    def __init__(self):\n",
    "        self._messages: List[Dict[str, str]] = []\n",
    "\n",
    "    def add_message(self,\n",
    "                    role: Literal['user', 'system', 'assistant', 'tool'],\n",
    "                    content: str,\n",
    "                    tool_calls: dict=dict(),\n",
    "                    tool_call_id=None)-> None:\n",
    "\n",
    "        message = {\n",
    "            \"role\": role,\n",
    "            \"content\": content,\n",
    "            \"tool_calls\": tool_calls,\n",
    "        }\n",
    "\n",
    "        if role == \"tool\":\n",
    "            message = {\n",
    "                \"role\": role,\n",
    "                \"content\": content,\n",
    "                \"tool_call_id\": tool_call_id,\n",
    "            }\n",
    "\n",
    "        self._messages.append(message)\n",
    "\n",
    "    def get_messages(self) -> List[Dict[str, str]]:\n",
    "        return self._messages\n",
    "\n",
    "    def last_message(self) -> None:\n",
    "        if self._messages:\n",
    "            return self._messages[-1]\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        self._messages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_tools(user_question:str=None,\n",
    "                    memory:Memory=None,\n",
    "                    model:str=\"gpt-4o-mini\",\n",
    "                    temperature=0.0,\n",
    "                    tools=None)-> str:\n",
    "    messages = [{\"role\": \"user\", \"content\": user_question}]\n",
    "\n",
    "    if memory:\n",
    "        if user_question:\n",
    "            memory.add_message(role=\"user\", content=user_question)\n",
    "        messages = memory.get_messages()\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model = model,\n",
    "        temperature = temperature,\n",
    "        messages = messages,\n",
    "        tools=tools,\n",
    "    )\n",
    "\n",
    "    ai_message = str(response.choices[0].message.content)\n",
    "    tool_calls = response.choices[0].message.tool_calls\n",
    "\n",
    "    if memory:\n",
    "        memory.add_message(role=\"assistant\", content=ai_message, tool_calls=tool_calls)\n",
    "\n",
    "    return ai_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power(base:float, exponent:float):\n",
    "    \"\"\"Exponentatiation: base to the power of exponent\"\"\"\n",
    "\n",
    "    return base ** exponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [{\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"power\",\n",
    "        \"description\": \"Exponentatiation: base to the power of exponent\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"base\": {\"type\": \"number\"},\n",
    "                \"exponent\": {\"type\": \"number\"}\n",
    "            },\n",
    "            \"required\": [\"base\", \"exponent\"],\n",
    "            \"additionalProperties\": False\n",
    "        },\n",
    "        \"strict\": True\n",
    "    }\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate memory and start with the system prompt\n",
    "memory = Memory()\n",
    "memory.add_message(role=\"system\", content=\"You're a helpful assitant\")\n",
    "\n",
    "# Call the LLM with a question that needs a tool\n",
    "ai_message = chat_with_tools(\n",
    "    \"2 to the power of -5?\",\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    tools=tools,\n",
    "    memory=memory,\n",
    ")\n",
    "\n",
    "# Get the arguments from the tool_calls object and call the actual defined function\n",
    "args = json.loads(memory.last_message()['tool_calls'][0].function.arguments)\n",
    "result = power(args[\"base\"], args[\"exponent\"])\n",
    "\n",
    "# Extract the tool_call_id and feed the LLM with the result from the function\n",
    "tool_call_id = memory.last_message()['tool_calls'][0].id\n",
    "memory.add_message(role=\"tool\", content=str(result), tool_call_id=tool_call_id)\n",
    "ai_message = chat_with_tools(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    tools=tools,\n",
    "    memory=memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': \"You're a helpful assitant\", 'tool_calls': {}},\n",
       " {'role': 'user', 'content': '2 to the power of -5?', 'tool_calls': {}},\n",
       " {'role': 'assistant',\n",
       "  'content': 'None',\n",
       "  'tool_calls': [ChatCompletionMessageFunctionToolCall(id='call_K4TPChiwiQwxZ0q26SY7i4BO', function=Function(arguments='{\"base\":2,\"exponent\":-5}', name='power'), type='function')]},\n",
       " {'role': 'tool',\n",
       "  'content': '0.03125',\n",
       "  'tool_call_id': 'call_K4TPChiwiQwxZ0q26SY7i4BO'},\n",
       " {'role': 'assistant',\n",
       "  'content': '2 to the power of -5 is 0.03125.',\n",
       "  'tool_calls': None}]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.get_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Tool abstractions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although powerful, the way we've built by calling manually is prone to errors. What if you don't pass the correct type or miss one required field in the json-schema?\n",
    "\n",
    "Your task is creating an abstraction to make it easier to build a tool and call it. \n",
    "\n",
    "Tip: Inspect the json schema of the tool we created to help you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your class should have at least the following methods: \n",
    "- `__init__()` receiving the function and some logic to extract docs, arguments and their types\n",
    "- `dict()` to return the json schema\n",
    "- `__call__()` to enable the object instantiated to be callable. \n",
    "\n",
    "Example:\n",
    "```python\n",
    "class Tool:\n",
    "    def __init__(self, func:Callable):\n",
    "        self.func = func\n",
    "    \n",
    "    def dict(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.func(*args, **kwargs)  \n",
    "\n",
    "def my_func(arg1:int)->str:\n",
    "    return \"ok\"\n",
    "\n",
    "my_tool = Tool(my_func)\n",
    "my_tool(arg1=1)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important learn about the following Python methods to understand how to parse functions and get docstrings, arguments and types:\n",
    "- typing.get_type_hints()\n",
    "- inspect.signature()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import get_type_hints\n",
    "\n",
    "class Tool:\n",
    "    def __init__(self, func:Callable):\n",
    "        self.func = func\n",
    "        self.name = func.__name__\n",
    "        self.args = inspect.getfullargspec(func).args\n",
    "        self.type_hints = get_type_hints(func)\n",
    "\n",
    "    def dict(self):\n",
    "        properties = {}\n",
    "        type_map = {\n",
    "            int: \"integer\",\n",
    "            float: \"number\",\n",
    "            str: \"string\",\n",
    "            bool: \"boolean\",\n",
    "            list: \"array\",\n",
    "            dict: \"object\",\n",
    "        }\n",
    "\n",
    "        for arg in self.args:\n",
    "            arg_type = self.type_hints.get(arg, str)\n",
    "            json_type = type_map.get(arg_type, \"string\")\n",
    "            properties[arg] = {\"type\": json_type}\n",
    "\n",
    "        return {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": self.func.__name__,\n",
    "                \"description\": self.func.__doc__,\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": properties,  # ✅ NOW POPULATED\n",
    "                    \"required\": self.args,\n",
    "                    \"additionalProperties\": False\n",
    "                },\n",
    "                \"strict\": True\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.func(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power(base:float, exponent:float):\n",
    "    \"\"\"Exponentatiation: base to the power of exponent\"\"\"\n",
    "\n",
    "    return base ** exponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_tool = Tool(power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'function',\n",
       " 'function': {'name': 'power',\n",
       "  'description': 'Exponentatiation: base to the power of exponent',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'base': {'type': 'number'}, 'exponent': {'type': 'number'}},\n",
       "   'required': ['base', 'exponent'],\n",
       "   'additionalProperties': False},\n",
       "  'strict': True}}"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "power_tool.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "power_tool(2,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Update the Agent class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will enhance the logic of your agent so that it can handle user queries and interact with external tools dynamically. The goal is to refine how the agent processes user messages, generates responses, and invokes tools when necessary.\n",
    "\n",
    "**Objective**\n",
    "\n",
    "You will modify the logic responsible for:\n",
    "\n",
    "- Processing user input – The agent should record and manage conversation history.\n",
    "- Generating a response – The agent will use a language model to create a reply based on previous messages.\n",
    "- Identifying when tools are needed – If a tool is required to complete the request, the agent should detect this and trigger the appropriate function.\n",
    "- Handling tool execution and responses – The agent should execute the tool, capture its output, and integrate the result into the conversation.\n",
    "\n",
    "**Steps**\n",
    "\n",
    "- Update the logic to check whether a tool needs to be invoked based on the AI-generated response.\n",
    "- If tools are needed, execute them with the correct arguments.\n",
    "- Incorporate tool results into the conversation so that the AI can refine its response using the additional information.\n",
    "- Ensure the agent can handle multiple tool calls recursively, meaning if the response suggests using another tool after the first one, it should be processed correctly.\n",
    "\n",
    "**Considerations**\n",
    "\n",
    "- Think about how the agent decides when to call a tool.\n",
    "- Ensure the agent stores the tool’s response correctly so it can continue the conversation naturally.\n",
    "- Handle cases where multiple tools might need to be used in sequence before the final response is given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    \"\"\"A tool-calling AI Agent\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        name:str = \"Agent\",\n",
    "        role:str = \"Personal Assistant\",\n",
    "        instructions:str = \"Help users with any question\",\n",
    "        model:str = \"gpt-4o-mini\",\n",
    "        temperature:float = 0.0,\n",
    "        tools:List[Tool] = [],\n",
    "    ):\n",
    "        self.name = name\n",
    "        self.role = role\n",
    "        self.instructions = instructions\n",
    "        self.model = model\n",
    "        self.temperature = temperature\n",
    "        self.memory = Memory()\n",
    "        self.memory.add_message(\n",
    "            role=\"system\",\n",
    "            content=f\"You're an AI Agent, your role is {self.role}, \"\n",
    "                    f\"and you need to {self.instructions}\",\n",
    "        )\n",
    "\n",
    "        self.client = OpenAI(\n",
    "            api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "            base_url=\"https://openai.vocareum.com/v1\"\n",
    "        )\n",
    "\n",
    "        self.tools = tools\n",
    "\n",
    "    def invoke(self, user_message: str) -> str:\n",
    "        # Add user message to memory\n",
    "        self.memory.add_message(role=\"user\", content=user_message)\n",
    "\n",
    "\n",
    "        # Convert tools to dict format\n",
    "        tools_dict = [tool.dict() for tool in self.tools]\n",
    "\n",
    "        # First API call\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            temperature=self.temperature,\n",
    "            messages=self.memory.get_messages(),\n",
    "            tools=tools_dict if tools_dict else None,\n",
    "        )\n",
    "\n",
    "        ai_message = response.choices[0].message.content or \"\"\n",
    "        tool_calls = response.choices[0].message.tool_calls\n",
    "\n",
    "        # Store AI response\n",
    "        self.memory.add_message(role=\"assistant\", content=ai_message, tool_calls=tool_calls)\n",
    "\n",
    "        # Handle tool calls\n",
    "        if tool_calls:\n",
    "            for tool_call in tool_calls:\n",
    "                tool_name = tool_call.function.name\n",
    "                tool_args = json.loads(tool_call.function.arguments)\n",
    "\n",
    "                # Find and execute the matching tool\n",
    "                for tool in self.tools:\n",
    "                    if tool.name == tool_name:\n",
    "                        try:\n",
    "                            result = tool(**tool_args)\n",
    "                            self.memory.add_message(\n",
    "                                role=\"tool\",\n",
    "                                content=str(result),\n",
    "                                tool_call_id=tool_call.id\n",
    "                            )\n",
    "                        except Exception as e:\n",
    "                            self.memory.add_message(\n",
    "                                role=\"tool\",\n",
    "                                content=f\"Error: {str(e)}\",\n",
    "                                tool_call_id=tool_call.id\n",
    "                            )\n",
    "                        break\n",
    "\n",
    "            # Ask AI again with tool results\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                temperature=self.temperature,\n",
    "                messages=self.memory.get_messages(),\n",
    "                tools=tools_dict if tools_dict else None,\n",
    "            )\n",
    "            ai_message = response.choices[0].message.content or \"\"\n",
    "            self.memory.add_message(role=\"assistant\", content=ai_message, tool_calls=response.choices[0].message.tool_calls)\n",
    "\n",
    "        return ai_message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build some agents and have fun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create some specific agents with  tools, invoke then and  inspect their memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pendulum\n",
    "def get_current_time(timezone: str) -> str:\n",
    "    \"\"\"Get the current time in a specific timezone.\"\"\"\n",
    "    try:\n",
    "        import pendulum\n",
    "        current_time = pendulum.now(timezone)\n",
    "        return current_time.format(\"YYYY-MM-DD HH:mm:ss ZZZ\")\n",
    "    except:\n",
    "        return \"Invalid timezone\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO  - Create a default agent passing the tools you created\n",
    "time_tool = Tool(get_current_time)\n",
    "agent = Agent(name=\"TimeAssistant\",\n",
    "    role=\"Time helper\",\n",
    "    instructions=\"Help users get current time in timezone in which they mention in the prompt\", tools=[time_tool])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The current time in Bucharest, Romania is 10:03 AM on March 1, 2026.'"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO - Ask it simple questions not related to the tools you created:\n",
    "agent.invoke(\"What's the time now in Bucharest, Romania?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': \"You're an AI Agent, your role is Time helper, and you need to Help users get current time in timezone in which they mention in the prompt\",\n",
       "  'tool_calls': {}},\n",
       " {'role': 'user',\n",
       "  'content': \"What's the time now in Bucharest, Romania?\",\n",
       "  'tool_calls': {}},\n",
       " {'role': 'assistant',\n",
       "  'content': '',\n",
       "  'tool_calls': [ChatCompletionMessageFunctionToolCall(id='call_St7tQCMyZqvgIifLS0uWC9G2', function=Function(arguments='{\"timezone\":\"Europe/Bucharest\"}', name='get_current_time'), type='function')]},\n",
       " {'role': 'tool',\n",
       "  'content': '2026-03-01 10:03:48 +0200+02:00',\n",
       "  'tool_call_id': 'call_St7tQCMyZqvgIifLS0uWC9G2'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'The current time in Bucharest, Romania is 10:03 AM on March 1, 2026.',\n",
       "  'tool_calls': None}]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO - Check its memory\n",
    "agent.memory.get_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Reset your agent's memory\n",
    "agent.memory.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The current time in Paris, France is 09:03 AM on March 1, 2026.'"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO - Ask it simple questions related to the tools you created:\n",
    "agent.invoke(\"What is the time now in Paris, France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'What is the time now in Paris, France?',\n",
       "  'tool_calls': {}},\n",
       " {'role': 'assistant',\n",
       "  'content': '',\n",
       "  'tool_calls': [ChatCompletionMessageFunctionToolCall(id='call_gglbBTY2oK3pdxRvY382aKBS', function=Function(arguments='{\"timezone\":\"Europe/Paris\"}', name='get_current_time'), type='function')]},\n",
       " {'role': 'tool',\n",
       "  'content': '2026-03-01 09:03:50 +0100+01:00',\n",
       "  'tool_call_id': 'call_gglbBTY2oK3pdxRvY382aKBS'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'The current time in Paris, France is 09:03 AM on March 1, 2026.',\n",
       "  'tool_calls': None}]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO - Check its memory again\n",
    "agent.memory.get_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The current time in Warsaw, Poland is 09:03 AM on March 1, 2026.'"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO - Ask it simple questions related to the tools you created:\n",
    "agent.invoke(\"What is the time now in Warsaw?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'What is the time now in Paris, France?',\n",
       "  'tool_calls': {}},\n",
       " {'role': 'assistant',\n",
       "  'content': '',\n",
       "  'tool_calls': [ChatCompletionMessageFunctionToolCall(id='call_gglbBTY2oK3pdxRvY382aKBS', function=Function(arguments='{\"timezone\":\"Europe/Paris\"}', name='get_current_time'), type='function')]},\n",
       " {'role': 'tool',\n",
       "  'content': '2026-03-01 09:03:50 +0100+01:00',\n",
       "  'tool_call_id': 'call_gglbBTY2oK3pdxRvY382aKBS'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'The current time in Paris, France is 09:03 AM on March 1, 2026.',\n",
       "  'tool_calls': None},\n",
       " {'role': 'user',\n",
       "  'content': 'What is the time now in Warsaw?',\n",
       "  'tool_calls': {}},\n",
       " {'role': 'assistant',\n",
       "  'content': '',\n",
       "  'tool_calls': [ChatCompletionMessageFunctionToolCall(id='call_ftOcGV3z9lZoShH7QytClURF', function=Function(arguments='{\"timezone\":\"Europe/Warsaw\"}', name='get_current_time'), type='function')]},\n",
       " {'role': 'tool',\n",
       "  'content': '2026-03-01 09:03:53 +0100+01:00',\n",
       "  'tool_call_id': 'call_ftOcGV3z9lZoShH7QytClURF'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'The current time in Warsaw, Poland is 09:03 AM on March 1, 2026.',\n",
       "  'tool_calls': None}]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO - Check its memory\n",
    "agent.memory.get_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Experiment\n",
    "\n",
    "Now that you understood how it works, experiment with new things.\n",
    "\n",
    "- Experiment new critique prompts\n",
    "- What happens when you increase the number of iterations?\n",
    "- Try accessing the memory to inspect it (agent.memory) instead of reading the outputs (verbose=False)\n",
    "- What else can you try?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
